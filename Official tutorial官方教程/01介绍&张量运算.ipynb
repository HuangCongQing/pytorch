{
 "cells": [
  {
   "source": [
    "参考：\n",
    "* 官网中文：https://pytorch.apachecn.org/docs/1.4/blitz/tensor_tutorial.html\n",
    "* 深度学习之Pytorch基础教程！\n",
    "： https://mp.weixin.qq.com/s/kDGHQQ_wRQXds34HHCQNOQ\n",
    "\n",
    "PyTorch是一个基于python的科学计算包，主要针对两类人群：\n",
    "\n",
    "* 作为NumPy的替代品，可以利用GPU的性能进行计算\n",
    "* 作为一个高灵活性、速度快的深度学习平台\n",
    "\n",
    "\n",
    "### 目录\n",
    "* 1 张量\n",
    "* 2 运算\n",
    "    * 算数运算\n",
    "    * 索引\n",
    "    * 改变形状\n",
    "* 3 广播机制\n",
    "* 4 Tensor和Numpy相互转化\n",
    "* 5  GPU运算"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 张量\n",
    "Tensor(张量）类似于NumPy的ndarray，但还可以在GPU上使用来加速计算。\n",
    "\n",
    "这些创建方法都可以在创建的时候**指定数据类型dtype和存放device(cpu/gpu)。**\n",
    "\n",
    "\n",
    "\n",
    "![](https://mmbiz.qpic.cn/mmbiz_png/vI9nYe94fsFfaUzHsEvJhbPArzshFk0NqR3RY4k3mwKZHCVPwkJTicyUhu53eKDqOuKt45jhMqaK7lEdiaXYDSvA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[4.7428e+30, 2.5062e-12, 1.4586e-19],\n        [8.1546e-33, 1.3563e-19, 1.6114e-19],\n        [1.8042e+28, 1.7899e+19, 1.6457e+19],\n        [1.4585e-19, 6.7421e+22, 5.0761e+31],\n        [1.3556e-19, 7.2053e+22, 4.7428e+30]])\n"
     ]
    }
   ],
   "source": [
    "# 创建未初始化的Tensor\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7685, 0.0247, 0.4373],\n        [0.8077, 0.9733, 0.8917],\n        [0.5988, 0.3023, 0.0215],\n        [0.1832, 0.5932, 0.4136],\n        [0.7592, 0.6733, 0.5404]])\n"
     ]
    }
   ],
   "source": [
    "# 创造随机初始化的Tensor  rand\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 全为0的Tensor  zeros\n",
    "x = torch.zeros(2,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 根据数据创建Tensor  tensor\n",
    "x = torch.tensor([2,3,4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([[0.1745, 0.3031, 0.4357],\n        [0.0771, 0.0306, 0.5096],\n        [0.5548, 0.6502, 0.4673],\n        [0.0561, 0.3961, 0.8094],\n        [0.1659, 0.1197, 0.2819]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 修改原Tensor为全1的Tensor\n",
    "x = x.new_ones(5,3,dtype=torch.float64)\n",
    "print(x)\n",
    "\n",
    "# 修改数据类型  rand_like   返回与输入相同大小的张量，该张量由区间[0,1)上均匀分布的随机数填充\n",
    "x = torch.rand_like(x,dtype=torch.float64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 3])\ntorch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取形状\n",
    "print(x.size())\n",
    "print(x.shape)\n",
    "\n",
    "# 输出torch.Size本质上还是tuple，所以支持tuple的一切操作。"
   ]
  },
  {
   "source": [
    "## 运算\n",
    "\n",
    "### 1 算数操作\n",
    "有三种加法运算\n",
    "* x+y\n",
    "* torch.add(x, y, , out=result)\n",
    "* y.add_(x)    print(y)  # add x to y\n",
    "\n",
    "> 注意：\n",
    "任何一个in-place改变张量的操作后面都固定一个_。例如x.copy_(y)、x.t_()将更改x"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.1745, 1.3031, 1.4357],\n        [1.0771, 1.0306, 1.5096],\n        [1.5548, 1.6502, 1.4673],\n        [1.0561, 1.3961, 1.8094],\n        [1.1659, 1.1197, 1.2819]], dtype=torch.float64)\ntensor([[1.1745, 1.3031, 1.4357],\n        [1.0771, 1.0306, 1.5096],\n        [1.5548, 1.6502, 1.4673],\n        [1.0561, 1.3961, 1.8094],\n        [1.1659, 1.1197, 1.2819]])\ntensor([[1.1745, 1.3031, 1.4357],\n        [1.0771, 1.0306, 1.5096],\n        [1.5548, 1.6502, 1.4673],\n        [1.0561, 1.3961, 1.8094],\n        [1.1659, 1.1197, 1.2819]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones(5,3)\n",
    "print(x+y)\n",
    "\n",
    "result = torch.rand(5,3)  # pytorch  NameError: name  result  is not defined\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "y.add_(x)\n",
    "print(y)\n"
   ]
  },
  {
   "source": [
    "### 2 索引\n",
    "* 需要注意的是：索引出来的结果与原数据共享内存，也即修改⼀个，另⼀个会跟着修改。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1.1745, 1.3031, 1.4357], dtype=torch.float64)\ntensor([1.1745, 1.3031, 1.4357], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = x[0, :]\n",
    "y+=1\n",
    "print(y)\n",
    "print(x[0,:])"
   ]
  },
  {
   "source": [
    "### 3 改变形状  view()\n",
    "* 类似reshape,但reshape不共享内存\n",
    "* -1所指的维度可以根据其他维度的值推出来\n",
    "* 注意 view() 返回的新tensor与源tensor共享内存（其实是同⼀个tensor），也即更改其中的⼀个，另 外⼀个也会跟着改变。(顾名思义，view仅是改变了对这个张量的观察角度)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(15)\n",
    "z = x.view(-1, 5)\n",
    "print(x.shape, y.shape, z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[2.1745, 2.3031, 2.4357],\n        [1.0771, 1.0306, 1.5096],\n        [1.5548, 1.6502, 1.4673],\n        [1.0561, 1.3961, 1.8094],\n        [1.1659, 1.1197, 1.2819]], dtype=torch.float64)\ntensor([2.1745, 2.3031, 2.4357, 1.0771, 1.0306, 1.5096, 1.5548, 1.6502, 1.4673,\n        1.0561, 1.3961, 1.8094, 1.1659, 1.1197, 1.2819], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x += 1\n",
    "print(x)  # 共享内存\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "#### 如果我们想返回⼀个真正新的副本（即不共享内存）该怎么办呢？Pytorch还提供了⼀ 个 reshape() 可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先 ⽤ clone 创造一个副本然后再使⽤ view 。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.1745, 1.3031, 1.4357],\n        [0.0771, 0.0306, 0.5096],\n        [0.5548, 0.6502, 0.4673],\n        [0.0561, 0.3961, 0.8094],\n        [0.1659, 0.1197, 0.2819]], dtype=torch.float64)\ntensor([2.1745, 2.3031, 2.4357, 1.0771, 1.0306, 1.5096, 1.5548, 1.6502, 1.4673,\n        1.0561, 1.3961, 1.8094, 1.1659, 1.1197, 1.2819], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_cp = x.clone().view(15)\n",
    "x -= 1\n",
    "print(x)\n",
    "print(x_cp)"
   ]
  },
  {
   "source": [
    "#### 另外⼀个常用的函数就是 item() ,如果是仅包含一个元素的tensor， 它可以将⼀个标量 Tensor 转换成⼀个Python数值"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.0538])\n-0.05384066700935364\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "source": [
    "### 后续阅读：\n",
    "\n",
    "超过100种tensor的运算操作，包括转置，索引，切片，数学运算， 线性代数，随机数等，具体访问这里\n",
    "https://pytorch.org/docs/stable/torch.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3 广播机制\n",
    "当对两个形状不同的 Tensor 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算。例如："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 2])\ntensor([[1],\n        [2],\n        [3]])\ntensor([[2, 3],\n        [3, 4],\n        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,3).view(1, 2)  # torch.arange(start=1, end=6)的结果并不包含end。torch.range(start=1, end=6) 的结果是会包含end的\n",
    "print(x)\n",
    "y = torch.arange(1,4).view(3, 1)\n",
    "print(y)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6.])\ntorch.float32\ntensor([0, 1, 2, 3, 4, 5])\ntorch.int64\n"
     ]
    }
   ],
   "source": [
    "    import torch\n",
    " \n",
    "    y = torch.range(1, 6)\n",
    " \n",
    "    print(y)\n",
    "    print(y.dtype)\n",
    " \n",
    "    z = torch.arange(0, 6)\n",
    "    print(z)\n",
    "    print(z.dtype)"
   ]
  },
  {
   "source": [
    "## 4 Tensor和Numpy相互转化\n",
    "\n",
    "我们很容易⽤** numpy() 和 from_numpy() **将 Tensor 和NumPy中的数组相互转换。\n",
    "\n",
    "* 但是需要注意的⼀点是：这两个函数所产生的的 Tensor 和NumPy中的数组共享相同的内存（所以他们之间的转换很快），改变其中⼀个时另⼀个也会改变！！！"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a += 1\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b += 1\n",
    "print(a,b)"
   ]
  },
  {
   "source": [
    "#### 使⽤ from_numpy() 将NumPy数组转换成 Tensor :\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a,b)"
   ]
  },
  {
   "source": [
    "## 5  GPU运算\n",
    "\n",
    "张量可以使用.to方法移动到任何设备(device）上：\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 3], device='cuda:0')\ntensor([2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 当GPU可用时,我们可以运行以下代码\n",
    "# 我们将使用`torch.device`来将tensor移入和移出GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # 直接在GPU上创建tensor\n",
    "    x = x.to(device)                       # 或者使用`.to(\"cuda\")`方法\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # `.to`也能在移动时改变dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('torch': conda)",
   "language": "python",
   "name": "python361264bittorchcondac32bb4459542487a904c87a0f2756d06"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}